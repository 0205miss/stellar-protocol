## Preamble

```
CAP: 0005
Title: Throttling and transaction pricing improvements 
Author: Nicolas Barry
Status: Draft
Created: 2018-Oct-05
Discussion: https://github.com/stellar/stellar-protocol/issues/75
https://github.com/stellar/stellar-protocol/issues/133
Protocol version: TBD
```

## Simple Summary
Combined set of changes that rationalize how we throttle the network, and also
makes it easier for clients to craft transactions that will make it into a ledger
even when network fees are changing rapidly.

## Abstract
 
Goal of the updated design is to maximize the number of operations included
in a _candidate_ transaction set, while preserving fairness.

Note that there are two mechanism at play here: one that is implemented to
construct _candidate_ values by validators which happens outside of consensus, and
the other mechanism that is used to pick between two candidate sets during
consensus.

Fairness in how transactions are included in a candidate set is equivalent to
designing a sorting scheme for the list of transactions _before_
trimming (typically all accumulated transactions on the validator) such that:
* accounts have the same odds of having their transactions included, regardless
of the distribution of transactions per account and regardless of how many
transactions are picked from the sorted set.
* transactions with a higher per operation fee have a strict advantage over lower
fee transactions.

Fairness is also achieved by attempting to _reduce_ the fee charged to accounts.

This is achieved by associating a value `baseFee` to each
transaction set (greater than `ledgerHeader.baseFee`), and using that base fee
to compute the actual fee charged.
With this change, `tx.fee` becomes an upper bound instead of being the actual
fee deducted from the source account.

## Motivation

Right now the network configuration that governs the maximum throughput of the
network is `ledgerHeader.maxTxSetSize`, that controls the maximum number of
 _transactions_ that can be included in a transaction set; yet a good approximation
of work (reflected in how fees are computed), is the total number of _operations_
included in a transaction set.
As any transaction can contain up to 100 operations, this causes the network
setting to be overly conservative (as it has to assume the worst case situation
where all transactions would be 100 operations).

Another motivation for changing how fees are computed is that right now the
fee charged for a given transaction is equal to the amount specified when the
transaction was crafted.

When surge pricing occurs, or simply if `ledgerHeader.baseFee` is raised, this
creates problems:
* for the typical user, this leads to transactions rejected by validators if the
specified fee is too small.
* for pre-signed transactions (smart contracts), the fee has to be specified with
a value that exceeds the future fee required to be included in a transaction set.
* in both cases the model can lead to excessive fees charged to users if the
specified fee is bigger than needed.

## Specification

### Transaction set `baseFee`

A new value gets associated to each transaction set during consensus: `txSetBaseFee`.

### XDR representation
The corresponding xdr looks like this:
```c++
struct StellarValueV1
{
    int64 txSetBaseFee; // base fee for the transaction set

    // reserved for future use
    union switch (int v)
    {
    case 0:
        void;
    }
    ext;
};

struct StellarValue
{
    Hash txSetHash;   // transaction set to apply to previous ledger
    uint64 closeTime; // network close time

    // upgrades to apply to the previous ledger (usually empty)
    // this is a vector of encoded 'LedgerUpgrade' so that nodes can drop
    // unknown steps during consensus if needed.
    // see notes below on 'LedgerUpgrade' for more detail
    // max size is dictated by number of upgrade types (+ room for future)
    UpgradeType upgrades<6>;

    union switch (int v)
    {
    case 0:
        void;
    case 1:
        StellarValueV1 v1;
    }
    ext;
};

struct LedgerHeader
{
//...
    // (was maxTxSetSize)
    uint32 txSetSize; // maximum size a transaction set can be
//...
};
```

### Construction of the pair (`txSetBaseFee`, `txSet`)
#### Repurposing `ledgerHeader.maxTxSetSize`

The network level setting `maxTxSetSize` gets renamed to `txSetSize`.

This setting controls the maximum number of _operations_ allowed in a
transaction set (currently it controls the number of _transactions_).

#### Updated "surge pricing" algorithm

1. pick a random number S
2. for each account, construct a queue of transactions for that account,
sorted by sequence number in ascending order
    * implementation note: there might be an opportunity to consolidate with
the transaction holding tank.
3. construct a heap of those queues, sorted by:
    * the fee rate (descending) of the first transaction in each queue (so that the queue
whose first transaction has the highest fee rate is on top of the heap)
     * account ID Xored with S (ascending)
4. `nb_operations_to_add = txSetSize`
5. while (`nb_operations_to_add > 0 && !heap.empty()`)
   * queue = heap.pop()
   * if nb_operations(first transaction "tx" from queue)  <= nb_operations_to_add
     * push tx into txSet
     * nb_operations_to_add = nb_operations_to_add - nb_operations(tx)
     * pop tx from queue
     * if queue non empty, push it into the heap
 6. if `(!heap.empty())` // surge pricing in effect
    * queue = heap.peek()
    * set `txSetBaseFee` to the fee rate of the first transaction from queue
    else do not set `txSetBaseFee` (`value.v == 0`)

Note: if `ledgerHeader.ledgerVersion < CAP_0005.protocolVersion`,
* step 4 becomes `nb_operations_to_add = txSetSize*100`
* in step 6, `txSetBaseFee` is not set (leave `value.v == 0`)

### Validity and usage of `txSetBaseFee`

`StellarValue` is considered valid if the following conditions are met:
1. the effective base fee is valid
  * `value.v() == 0` (use `ledgerHeader.baseFee`) or
  * `value.v() == 1` and
    * `ledgerHeader.ledgerVersion >= CAP_0005.protocolVersion` // supported
    * `value.v1().txSetBaseFee >= ledgerHeader.baseFee`
2. The transaction set is valid given the effective base fee
  * for each transaction ensure that `tx.fee >= computedFee(effectiveBaseFee)`, with:
    * if `ledgerHeader.ledgerVersion >= CAP_0005.protocolVersion`
        * `computedFee(tx, effectiveBaseFee) = effectiveBaseFee * tx.ops.length()`
    * otherwise (current)
        * `computedFee(tx, effectiveBaseFee) = tx.fee`
  * each source account has a sufficient balance to cover the combined computed
fees of that account's transactions.

When applying a transaction set, each transaction collects a fee equal
to `computedFee(tx, effectiveBaseFee)`.

There is a question of what a valid base fee is (step 1), in addition to what
is described here: without any other limitation, a (bad) validator can nominate
the same value with `txSetBaseFee` set to its highest possible value.
The highest possible value is the highest base fee that the last transaction can
pay for.

As the value nominated by a given validator is considered by other validators with
some probability, a good mitigation could be to cap increases in base fee, and not
have a cap on decreases:
* assuming that most of the time values come from well behaved validators, this
will lower the base fee to the desired (smaller) value
* increases in base fee will be conditioned by a maximum rate of increase (let's
 say a maximum factor of 2)
 
In addition to this, historical votes of the various validators should be available
for review as to identify mis behaving validators.

### Ballot protocol changes

The ballot protocol requires a function to combine candidate values produced by
the nomination protocol.

For older versions of the protocol, we do not change this function, ie we keep
the transaction set with the highest number of transactions, and break ties
 by comparing the hash of transaction sets (xored to pseudo-randomize).

For newer versions of the protocol, we'll be following a similar scheme by
picking the highest value sorted in order by:
* highest number of operations
* highest base fee
* highest txset hash (xored by the hash of all value as before)


### Changes to transaction submission

When a standalone transaction is received by a validator, the transaction gets
added to the source's account's transaction queue if:
1. the sequence numbers are valid.
2. it replaces an existing transaction with the same sequence number but has a
higher `fee`.
3. the account can pay for all fees.
4. the transaction is valid (signatures are valid, the transaction and its
operations are valid)

Implementation note: there might be a way to implicitely perform steps 1..3 by
chosing a good datastructure.

## Rationale

Implementing this proposal should greatly increase the chances of transactions
being processed by the network even when fees vary between ledgers.

More improvements can be made, in particular for very long lived pre-signed
transactions (where there is no rational way of putting a high bound on fees),
or for more complex client side fee control strategies.

This proposal assumes that there is no inherent incentive in validators
profiting from the rise of fees which probably stays true for the foreseable
future.

## Backwards Compatibility

### Transaction subsystem
The change is backward compatible with existing transactions and will be
transparent to clients.

The only breaking change is that accounts may have a higher balance than
expected if `fee` is higher than the minimum fee.

Smart contracts typically don't rely on exact balances and use `mergeAccountOp`
as part of their cleanup.

### Network

Validators must run a version of the software that supports this new model.

To avoid nominating values that would not be compatible with other nodes on the
network, validators will only set `txSetBaseFee` when the network has already
upgraded to a version of the protocol compatible with this CAP.

After the network upgrades to the new protocol version the value of `txSetSize`
will be smaller than desired (as the raw value will not represent transactions
but operations instead); A subsequent vote by validators will be need to be
coordinated in order to adjust it to a new desired value.

Practically speaking the disruption should be minimal:
* Most transactions are single operation transactions and won't be effected.
* Disruption will be mostly for transactions with more operations
than `txSetSize`. As of this writing, this network parameter is set to `50` on
the public network, which means that transactions with more than `50` operations
will not be accepted by the network during the two upgrades.
* Validators can coordinate a "double upgrade", where both the protocol version
and the `txSetSize` field gets updated.

## Test Cases

TBD

## Implementation

TBD
